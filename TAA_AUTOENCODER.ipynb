{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n",
      "WARNING:root:Debug message: No module named 'caffe2.python.caffe2_pybind11_state_gpu'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Necessities imported!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot\n",
    "import caffe2\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import operator\n",
    "import caffe2.python.predictor.predictor_exporter as pe\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "from caffe2.python import (\n",
    "    brew,\n",
    "    core,\n",
    "    model_helper,\n",
    "    net_drawer,\n",
    "    optimizer,\n",
    "    visualize,\n",
    "    workspace,\n",
    ")\n",
    "\n",
    "# If you would like to see some really detailed initializations,\n",
    "# you can change --caffe2_log_level=0 to --caffe2_log_level=-1\n",
    "core.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n",
    "print(\"Necessities imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateSequence(index,seqSize,noisyDatPath,refDatPath):\n",
    "    noisySeq = []\n",
    "    refSeq = []\n",
    "    imgList = os.listdir(noisyDatPath)\n",
    "    imgList.sort()\n",
    "   \n",
    "    if((index+seqSize)>len(imgList)):\n",
    "        seqSize = len(imgList) - index\n",
    "  \n",
    "    for i in range(seqSize):\n",
    "        noisyImg = cv2.imread(noisyDatPath+\"//\"+imgList[index+i])\n",
    "        refImg   = cv2.imread(refDatPath+\"//\"+imgList[index+i])\n",
    "        #noisyImg = cv2.imread(noisyDatPath+\"//\"+imgList[index+i])\n",
    "        #refImg   = cv2.imread(refDatPath+\"//\"+imgList[index+i])\n",
    "        noisySeq.append(noisyImg)\n",
    "        refSeq.append(refImg)\n",
    "    \n",
    "        \n",
    "    return noisySeq,refSeq\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateSubseqence(srcNoisyImg,srcRefImg,seqSize,subSeqSize):\n",
    "    \n",
    "    noisySubSeq = []\n",
    "    refSubSeq = []\n",
    "    subSeqWindow = 32 #trying to create subimages of size 32x32, paper works with 128x128\n",
    "\n",
    "    width,height = noisySeq[0].shape[0],noisySeq[0].shape[1]\n",
    "    \n",
    "    for k in range(subSeqSize):\n",
    "        initW = random.randint(0,width-subSeqWindow-1)\n",
    "        initH = random.randint(0,height-subSeqWindow-1)\n",
    "        for i in range(seqSize):\n",
    "            if(i>len(srcNoisyImg)-1):\n",
    "                break\n",
    "            subImageNoisy = srcNoisyImg[i][initW:initW+subSeqWindow,initH:initH+subSeqWindow,:3]\n",
    "            subImageRef   = srcRefImg[i][initW:initW+subSeqWindow,initH:initH+subSeqWindow,:3]\n",
    "            wN,hN = subImageRef.shape[0],subImageRef.shape[1]\n",
    "            if((wN != subSeqWindow) or(hN != subSeqWindow)):\n",
    "                print(\"width or height does not match:\"+str(wN)+\"x\"+str(hN)+\" initW:\"+str(initW)+\":\"+str(initW+subSeqWindow)+\" initH:\"+str(initH)+\":\"+str(initH+subSeqWindow))\n",
    "            noisySubSeq.append(subImageNoisy)\n",
    "            refSubSeq.append(subImageRef)\n",
    "        \n",
    "    return noisySubSeq,refSubSeq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImage(img):\n",
    "    pyplot.figure()\n",
    "    pyplot.subplot(1,2,1)\n",
    "    pyplot.imshow(img)\n",
    "    pyplot.axis('on')\n",
    "    pyplot.title('Original image = RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONV_KERNEL_SIZE  = 3\n",
    "CONV_KERNEL_PADING = 1\n",
    "def AddRecurrentBlock(model,data,layerNo):\n",
    "    convR1 = brew.conv(model, data, 'conv1', dim_in=1, dim_out=20, kernel=5)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddEncoderDecoder(model, data):\n",
    "    \n",
    "    #ENCODER PART\n",
    "    # Image size: 32 x 32 -> 32 x 32\n",
    "    conv1 = AddRecurrentBlock(model,data,1)\n",
    "    # Image size: 32 x 32 -> 16 x 16\n",
    "    pool1 = brew.max_pool(model, conv1, 'pool1', kernel=2, stride=2)\n",
    "\n",
    "    # Image size: 16 x 16 -> 16 x 16\n",
    "    conv2 = AddRecurrentBlock(model,pool1,2)\n",
    "    # Image size: 8x8 -> 8x8\n",
    "    pool2 = brew.max_pool(model, conv2, 'pool2', kernel=2, stride=2)\n",
    "    \n",
    "    # Image size: 8x8 -> 8 x 8\n",
    "    conv3 = AddRecurrentBlock(model,pool2,3)\n",
    "    # Image size: 8x8 -> 4x4\n",
    "    pool3 = brew.max_pool(model, conv3, 'pool3', kernel=2, stride=2)\n",
    "    \n",
    "    # Image size: 4x4 -> 4x4\n",
    "    conv4 = AddRecurrentBlock(model,pool3,4)\n",
    "    \n",
    "    ###DECODER PART\n",
    "    upconv3 = brew.conv_transpose(model, conv4, \"upcon3\", dim_in=101, dim_out=101, kernel=3, pad=1)\n",
    "    upsample3 = brew.conv_transpose(model, upconv3, \"upsample3\", dim_in=101, dim_out=101, kernel=2, stride=2)\n",
    "    \n",
    "    upconv2 = brew.conv_transpose(model, upsample3, \"upcon2\", dim_in=101, dim_out=76, kernel=3, pad=1)\n",
    "    upsample2 = brew.conv_transpose(model, upconv2, \"upsample2\", dim_in=76, dim_out=76, kernel=2, stride=2)\n",
    "    \n",
    "    upconv1 = brew.conv_transpose(model, conv2, \"upcon1\", dim_in=76, dim_out=1, kernel=3, pad=1)\n",
    "    upsample1 = brew.conv_transpose(model, upconv1, \"upsample1\", dim_in=1, dim_out=1, kernel=2, stride=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisyTraining = \"//home//rohit//Rohit//Internship//caffe//projects//ML_TAA//data//trainingData//Noisy\"\n",
    "refTraining = \"//home//rohit//Rohit//Internship//caffe//projects//ML_TAA//data//trainingData//Ref\"\n",
    "i = 0\n",
    "if(len(os.listdir(noisyTraining)) !=  len(os.listdir(refTraining))):\n",
    "    print(\"Error: Training and ref sizes match!\")\n",
    "\n",
    "dirSize = len(os.listdir(noisyTraining))\n",
    "seqSize = 3\n",
    "subSeqSize = 3\n",
    "\n",
    "while(i < dirSize):\n",
    "    noisySeq,refSeq = generateSequence(i,seqSize,noisyTraining,refTraining)\n",
    "    noisySubSeq,refSubSeq = generateSubseqence(noisySeq,refSeq,seqSize,subSeqSize)\n",
    "    \n",
    "    '''if i == 0:\n",
    "        for k in range(len(noisySubSeq)):\n",
    "            showImage(noisySubSeq[k])\n",
    "            showImage(refSubSeq[k])'''\n",
    "    i+=seqSize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(i < dirSize):\n",
    "    noisySeq,refSeq = generateSequence(i,seqSize,noisyTraining,refTraining);\n",
    "    \n",
    "    i+=seqSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
