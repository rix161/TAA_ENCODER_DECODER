{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n",
      "WARNING:root:Debug message: No module named 'caffe2.python.caffe2_pybind11_state_gpu'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Necessities imported!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot\n",
    "import caffe2\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import operator\n",
    "import caffe2.python.predictor.predictor_exporter as pe\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import lmdb\n",
    "\n",
    "from caffe2.python import core, utils, workspace\n",
    "from caffe2.proto import caffe2_pb2\n",
    "\n",
    "from caffe2.python import (\n",
    "    brew,\n",
    "    core,\n",
    "    model_helper,\n",
    "    net_drawer,\n",
    "    optimizer,\n",
    "    visualize,\n",
    "    workspace,\n",
    ")\n",
    "\n",
    "# If you would like to see some really detailed initializations,\n",
    "# you can change --caffe2_log_level=0 to --caffe2_log_level=-1\n",
    "core.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n",
    "print(\"Necessities imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateSequence(index,seqSize,noisyDatPath,refDatPath):\n",
    "    noisySeq = []\n",
    "    refSeq = []\n",
    "    imgList = os.listdir(noisyDatPath)\n",
    "    imgList.sort()\n",
    "   \n",
    "    if((index+seqSize)>len(imgList)):\n",
    "        seqSize = len(imgList) - index\n",
    "  \n",
    "    for i in range(seqSize):\n",
    "        noisyImg = cv2.imread(noisyDatPath+\"//\"+imgList[index+i])\n",
    "        refImg   = cv2.imread(refDatPath+\"//\"+imgList[index+i])\n",
    "        #noisyImg = cv2.imread(noisyDatPath+\"//\"+imgList[index+i])\n",
    "        #refImg   = cv2.imread(refDatPath+\"//\"+imgList[index+i])\n",
    "        noisySeq.append(noisyImg)\n",
    "        refSeq.append(refImg)\n",
    "    \n",
    "        \n",
    "    return noisySeq,refSeq\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateSubseqence(srcNoisyImg,srcRefImg,seqSize,subSeqSize):\n",
    "    \n",
    "    noisySubSeq = []\n",
    "    refSubSeq = []\n",
    "    subSeqWindow = 32 #trying to create subimages of size 32x32, paper works with 128x128\n",
    "\n",
    "    width,height = noisySeq[0].shape[0],noisySeq[0].shape[1]\n",
    "    \n",
    "    for k in range(subSeqSize):\n",
    "        initW = random.randint(0,width-subSeqWindow-1)\n",
    "        initH = random.randint(0,height-subSeqWindow-1)\n",
    "        for i in range(seqSize):\n",
    "            if(i>len(srcNoisyImg)-1):\n",
    "                break\n",
    "            subImageNoisy = srcNoisyImg[i][initW:initW+subSeqWindow,initH:initH+subSeqWindow,:3]\n",
    "            subImageRef   = srcRefImg[i][initW:initW+subSeqWindow,initH:initH+subSeqWindow,:3]\n",
    "            wN,hN = subImageRef.shape[0],subImageRef.shape[1]\n",
    "            if((wN != subSeqWindow) or(hN != subSeqWindow)):\n",
    "                print(\"width or height does not match:\"+str(wN)+\"x\"+str(hN)+\" initW:\"+str(initW)+\":\"+str(initW+subSeqWindow)+\" initH:\"+str(initH)+\":\"+str(initH+subSeqWindow))\n",
    "            noisySubSeq.append(subImageNoisy)\n",
    "            refSubSeq.append(subImageRef)\n",
    "        \n",
    "    return noisySubSeq,refSubSeq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImage(img):\n",
    "    pyplot.figure()\n",
    "    pyplot.subplot(1,2,1)\n",
    "    pyplot.imshow(img)\n",
    "    pyplot.axis('on')\n",
    "    pyplot.title('Original image = RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_db(db_type, db_name, imgSeq, refSeq):\n",
    "    db = core.C.create_db(db_type, db_name, core.C.Mode.write)\n",
    "    transaction = db.new_transaction()\n",
    "    for i in range(len(imgSeq)):\n",
    "        feature_and_label = caffe2_pb2.TensorProtos()\n",
    "        feature_and_label.protos.extend([\n",
    "            utils.NumpyArrayToCaffe2Tensor(imgSeq[i]),\n",
    "            utils.NumpyArrayToCaffe2Tensor(refSeq[i])])\n",
    "        transaction.put(\n",
    "            'train_%03d'.format(i),\n",
    "            feature_and_label.SerializeToString())\n",
    "    # Close the transaction, and then close the db.\n",
    "    del transaction\n",
    "    del db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisyTraining = \"//home//rohit//Rohit//Internship//caffe//projects//ML_TAA//data//trainingData//Noisy\"\n",
    "refTraining = \"//home//rohit//Rohit//Internship//caffe//projects//ML_TAA//data//trainingData//Ref\"\n",
    "\n",
    "i = 0\n",
    "if(len(os.listdir(noisyTraining)) !=  len(os.listdir(refTraining))):\n",
    "    print(\"Error: Training and ref sizes match!\")\n",
    "\n",
    "dirSize = len(os.listdir(noisyTraining))\n",
    "seqSize = 3\n",
    "subSeqSize = 3\n",
    "totalNoisyImage = []\n",
    "totalRefImage = []\n",
    "\n",
    "while(i < dirSize):\n",
    "    noisySeq,refSeq = generateSequence(i,seqSize,noisyTraining,refTraining)\n",
    "    noisySubSeq,refSubSeq = generateSubseqence(noisySeq,refSeq,seqSize,subSeqSize)\n",
    "    totalNoisyImage.extend(noisySubSeq)\n",
    "    totalRefImage.extend(refSubSeq)\n",
    "\n",
    "    '''if i == 0:\n",
    "        for k in range(len(noisySubSeq)):\n",
    "            showImage(noisySubSeq[k])\n",
    "            showImage(refSubSeq[k])'''\n",
    "    i+=seqSize\n",
    "\n",
    "write_db(\"minidb\", \"//home//rohit//Rohit//Internship//TAA_ML//ML_TAA.minidb\", totalNoisyImage,totalRefImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddInput(model, batch_size, db, db_type):\n",
    "    noisyImg_uint8,refImg_uint8 = model.TensorProtosDBInput([], [\"noisyImg_uint8\", \"refImg_uint8\"], batch_size=batch_size,\n",
    "        db=db, db_type=db_type)\n",
    "    \n",
    "    noisyImg = model.Cast(noisyImg_uint8, \"noisyImg\", to=core.DataType.FLOAT)\n",
    "    # scale data from [0,255] down to [0,1]\n",
    "    noisyImg = model.Scale(noisyImg, noisyImg, scale=float(1./256))\n",
    "    # don't need the gradient for the backward pass\n",
    "    noisyImg = model.StopGradient(noisyImg, noisyImg)\n",
    "    \n",
    "    \n",
    "    refImg = model.Cast(refImg_uint8, \"refImg\", to=core.DataType.FLOAT)\n",
    "    # scale data from [0,255] down to [0,1]\n",
    "    refImg = model.Scale(refImg, refImg, scale=float(1./256))\n",
    "    # don't need the gradient for the backward pass\n",
    "    refImg = model.StopGradient(refImg, refImg)\n",
    "    \n",
    "    return noisyImg, refImg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONV_KERNEL_SIZE  = 3\n",
    "\n",
    "CONV_KERNEL_PADING1 = 1\n",
    "CONV_KERNEL_STRIDE1 = 1\n",
    "\n",
    "CONV_KERNEL_PADING2 = 4\n",
    "CONV_KERNEL_STRIDE2 = 3\n",
    "\n",
    "def AddRecurrentBlock(model,data,layerNo,hiddenLayer,filter_count_in,filter_count_out):\n",
    "    #convR1 = brew.conv(model, data, 'conv1', dim_in=3, dim_out=20, kernel=3,pad_t=1,pad_l=4,pad_r=4,pad_b=1,stride = 1)\n",
    "   \n",
    "    convR1 = brew.conv(model,data,\"convR1\"+str(layerNo),dim_in=filter_count_in,dim_out=filter_count_out,\n",
    "                       kernel=CONV_KERNEL_SIZE,stride = CONV_KERNEL_STRIDE1,pad = CONV_KERNEL_PADING1)\n",
    "    \n",
    "    conCatR1,conCatDimsR1 = model.net.Concat( [convR1, hiddenLayer], ['concatR1'+str(layerNo), 'conCatDimsR1'+str(layerNo)], axis=2)\n",
    "    \n",
    "    convR2 = brew.conv(model,conCatR1,\"convR2\"+str(layerNo),dim_in=filter_count_out,dim_out=filter_count_out,\n",
    "                       kernel=CONV_KERNEL_SIZE,\n",
    "                       pad_t = 1,\n",
    "                       pad_b = 1,\n",
    "                       pad_l = 0,\n",
    "                       pad_r = 1,\n",
    "                       stride_w = 2,\n",
    "                       stride_h = 1)\n",
    "    \n",
    "    convR3 = brew.conv(model,data,\"convR3\"+str(layerNo),dim_in=filter_count_in,dim_out=filter_count_out,\n",
    "                       kernel=CONV_KERNEL_SIZE,stride = CONV_KERNEL_STRIDE1,pad = CONV_KERNEL_PADING1)\n",
    "    hiddenLayer = convR3\n",
    "    \n",
    "    return convR3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddEncoderDecoder(model, noisyData):\n",
    "    #creating recurrent hidden layers\n",
    "    hidden1 = train_model.param_init_net.XavierFill([], 'hidden1', shape=[seqSize,32,32,8])\n",
    "    #weights1 = train_model.param_init_net.XavierFill([], 'weights1', shape=[seqSize,32,32,8])\n",
    "    #bias1 = train_model.param_init_net.XavierFill([], 'bias1', shape=[seqSize,32,32,8])\n",
    "    hidden2 = train_model.param_init_net.XavierFill([], 'hidden2', shape=[seqSize,16,16,16])\n",
    "    #weights2 = train_model.param_init_net.XavierFill([], 'weights2', shape=[seqSize,16,16,16])\n",
    "    #bias2 = train_model.param_init_net.XavierFill([], 'bias2', shape=[seqSize,16,16,16])\n",
    "    hidden3 = train_model.param_init_net.XavierFill([], 'hidden3', shape=[seqSize,8,8,32])\n",
    "    hidden4 = train_model.param_init_net.XavierFill([], 'hidden4', shape=[seqSize,4,4,64])\n",
    "    \n",
    "    #ENCODER PART\n",
    "    # Image size: 32 x 32 -> 32 x 32\n",
    "    conv1 = AddRecurrentBlock(model,noisyData,1,hidden1,3,8)\n",
    "    # Image size: 32 x 32 -> 16 x 16\n",
    "    pool1 = brew.max_pool(model, conv1, 'pool1', kernel = 2, stride = 2)\n",
    "\n",
    "    # Image size: 16 x 16 -> 16 x 16\n",
    "    conv2 = AddRecurrentBlock(model,pool1,2,hidden2,8,16)\n",
    "    # Image size: 8x8 -> 8x8\n",
    "    pool2 = brew.max_pool(model, conv2, 'pool2', kernel=2, stride=2)\n",
    "    \n",
    "    # Image size: 8x8 -> 8 x 8\n",
    "    conv3 = AddRecurrentBlock(model,pool2,3,hidden3,16,32)\n",
    "    # Image size: 8x8 -> 4x4\n",
    "    pool3 = brew.max_pool(model, conv3, 'pool3', kernel=2, stride=2)\n",
    "    \n",
    "    # Image size: 4x4 -> 4x4\n",
    "    conv4 = AddRecurrentBlock(model,pool3,4,hidden4,32,64)\n",
    "    \n",
    "    ###DECODER PART\n",
    "    \n",
    "    upconv3 = brew.conv_transpose(model, conv4, \"upcon3\", dim_in=64, dim_out=32, kernel=3, pad=1)\n",
    "    upsample3 = brew.conv_transpose(model, upconv3, \"upsample3\", dim_in=32, dim_out=32, kernel=2, stride=2)\n",
    "    conCatD3,conCatDimsD3 = model.net.Concat( [upsample3, conv3], ['concatD3', 'conCatDimsD3'], axis=2)\n",
    "    convD3 = brew.conv(model,conCatD3,\"convD3\",dim_in=32,dim_out=32,\n",
    "                       kernel=3,\n",
    "                       pad_t = 1,\n",
    "                       pad_b = 1,\n",
    "                       pad_l = 0,\n",
    "                       pad_r = 1,\n",
    "                       stride_w = 2,\n",
    "                       stride_h = 1)\n",
    "    \n",
    "    upconv2 = brew.conv_transpose(model, upsample3, \"upcon2\", dim_in=32, dim_out=16, kernel=3, pad=1)\n",
    "    upsample2 = brew.conv_transpose(model, upconv2, \"upsample2\", dim_in=16, dim_out=16, kernel=2, stride=2)\n",
    "    conCatD2,conCatDimsD2 = model.net.Concat( [upsample2, conv2], ['concatD2', 'conCatDimsD2'], axis=2)\n",
    "    convD2 = brew.conv(model,conCatD2,\"convD2\",dim_in=16,dim_out=16,kernel=3,\n",
    "                       pad_t = 1,\n",
    "                       pad_b = 1,\n",
    "                       pad_l = 0,\n",
    "                       pad_r = 1,\n",
    "                       stride_w = 2,\n",
    "                       stride_h = 1)\n",
    "    \n",
    "    upconv1 = brew.conv_transpose(model, convD2, \"upcon1\", dim_in=16, dim_out=8, kernel=3, pad=1)\n",
    "    upsample1 = brew.conv_transpose(model, upconv1, \"upsample1\", dim_in=8, dim_out=8, kernel=2, stride=2)\n",
    "    conCatD1,conCatDimsD1 = model.net.Concat( [upsample1, conv1], ['concatD1', 'conCatDimsD1'], axis=2)\n",
    "    convD1 = brew.conv(model,conCatD1,\"convD1\",dim_in=8,dim_out=3,kernel=3,\n",
    "                       pad_t = 1,\n",
    "                       pad_b = 1,\n",
    "                       pad_l = 0,\n",
    "                       pad_r = 1,\n",
    "                       stride_w = 2,\n",
    "                       stride_h = 1)\n",
    "    \n",
    "    return convD1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addLosses(model,genImg,refImg):\n",
    "    ws = 0.8\n",
    "    wg = 0.1\n",
    "    wt = 0.1\n",
    "    #Add Spatial Loss]\n",
    "    dist = model.L1Distance(['convD1',refImg],\"dist\")\n",
    "    Ls = model.AveragedLoss(dist, \"loss\")\n",
    "    #Add Gradient Loss\n",
    "    Lg = 0\n",
    "    #Add Temporal Loss\n",
    "    Lt = 0\n",
    "    \n",
    "    return (Ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: L1Distance.\n"
     ]
    }
   ],
   "source": [
    "arg_scope = {\"order\": \"NHWC\"}\n",
    "# Create the model helper for the train model\n",
    "train_model = model_helper.ModelHelper(name=\"mnist_train\", arg_scope=arg_scope)\n",
    "\n",
    "# Specify the input is from the train lmdb\n",
    "noisyImg, refImg = AddInput(\n",
    "    train_model, batch_size=seqSize,\n",
    "    db = \"//home//rohit//Rohit//Internship//TAA_ML//ML_TAA.minidb\",\n",
    "    db_type = \"minidb\")\n",
    "\n",
    "genImg = AddEncoderDecoder(train_model,noisyImg)\n",
    "Loss = addLosses(train_model,genImg,refImg)\n",
    "train_model.AddGradientOperators([Loss])\n",
    "optimizer.build_adam(train_model, base_learning_rate=0.0001)\n",
    "\n",
    "workspace.RunNetOnce(train_model.param_init_net)\n",
    "workspace.CreateNet(train_model.net, overwrite=True)\n",
    "\n",
    "workspace.RunNet(train_model.Proto().name)\n",
    "finalBlob = workspace.FetchBlob(\"convD1\")\n",
    "refBlob = workspace.FetchBlob(\"refImg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
